# remove the non-significant predictors p > 0.05
npp.pred.names <- names(which(summary(aic.model)$coefficients[,4][2:length(summary(aic.model)$coefficients)] < 0.001))
# find the index of these predictors
pred.index <- which(colnames(reduced.pred) %in% npp.pred.names)
# use the index to pull out the final data
final.pred <- reduced.pred[,c(1,pred.index)]
# run the final regression
model.final <- lm(npp ~ .,
data = final.pred)
summary(model.final)
# remove the predictors that are too correlated
reduced.pred <- rem.cors(mlbs)
# run an OLS with the above predictors
npp.model <- lm(npp ~ .,
data = reduced.pred)
summary(npp.model)
# run a backwards stepwise regression
library(MASS)
aic.model <- stepAIC(npp.model, k = 2, trace = F)
# remove the non-significant predictors p > 0.05
npp.pred.names <- names(which(summary(aic.model)$coefficients[,4][2:length(summary(aic.model)$coefficients)] < 0.001))
# find the index of these predictors
pred.index <- which(colnames(reduced.pred) %in% npp.pred.names)
# use the index to pull out the final data
final.pred <- reduced.pred[,c(1,pred.index)]
# run the final regression
model.final <- lm(npp ~ .,
data = final.pred)
summary(model.final)
# remove the predictors that are too correlated
reduced.pred <- rem.cors(harv)
# run an OLS with the above predictors
npp.model <- lm(npp ~ .,
data = reduced.pred)
summary(npp.model)
# run a backwards stepwise regression
library(MASS)
aic.model <- stepAIC(npp.model, k = 2, trace = F)
# remove the non-significant predictors p > 0.05
npp.pred.names <- names(which(summary(aic.model)$coefficients[,4][2:length(summary(aic.model)$coefficients)] < 0.001))
# find the index of these predictors
pred.index <- which(colnames(reduced.pred) %in% npp.pred.names)
# use the index to pull out the final data
final.pred <- reduced.pred[,c(1,pred.index)]
# run the final regression
model.final <- lm(npp ~ .,
data = final.pred)
summary(model.final)
# remove the predictors that are too correlated
reduced.pred <- rem.cors(serc)
# run an OLS with the above predictors
npp.model <- lm(npp ~ .,
data = reduced.pred)
summary(npp.model)
# run a backwards stepwise regression
library(MASS)
aic.model <- stepAIC(npp.model, k = 2, trace = F)
# remove the non-significant predictors p > 0.05
npp.pred.names <- names(which(summary(aic.model)$coefficients[,4][2:length(summary(aic.model)$coefficients)] < 0.001))
# find the index of these predictors
pred.index <- which(colnames(reduced.pred) %in% npp.pred.names)
# use the index to pull out the final data
final.pred <- reduced.pred[,c(1,pred.index)]
# run the final regression
model.final <- lm(npp ~ .,
data = final.pred)
summary(model.final)
# remove the predictors that are too correlated
reduced.pred <- rem.cors(alls)
# run an OLS with the above predictors
npp.model <- lm(npp ~ .,
data = reduced.pred)
summary(npp.model)
# run a backwards stepwise regression
library(MASS)
aic.model <- stepAIC(npp.model, k = 2, trace = F)
# remove the non-significant predictors p > 0.05
npp.pred.names <- names(which(summary(aic.model)$coefficients[,4][2:length(summary(aic.model)$coefficients)] < 0.001))
# find the index of these predictors
pred.index <- which(colnames(reduced.pred) %in% npp.pred.names)
# use the index to pull out the final data
final.pred <- reduced.pred[,c(1,pred.index)]
# run the final regression
model.final <- lm(npp ~ .,
data = final.pred)
summary(model.final)
# take the column average for each site from the previous data
tall.avg <- as.data.frame(colMeans(tall))
mlbs.avg <- as.data.frame(colMeans(mlbs))
serc.avg <- as.data.frame(colMeans(serc))
harv.avg <- as.data.frame(colMeans(harv))
ornl.avg <- as.data.frame(colMeans(ornl))
# read in the bioclimatic data
tall.bio <- read.csv("C:/Users/Aaron Kamoske/Dropbox/Publications/Kamoske_Dissteration_Ch3/data/bioclim/tall2018_bioclim_20200205.csv")
serc.bio <- read.csv("C:/Users/Aaron Kamoske/Dropbox/Publications/Kamoske_Dissteration_Ch3/data/bioclim/serc2017_bioclim_20200205.csv")
ornl.bio <- read.csv("C:/Users/Aaron Kamoske/Dropbox/Publications/Kamoske_Dissteration_Ch3/data/bioclim/ornl2018_bioclim_20200205.csv")
mlbs.bio <- read.csv("C:/Users/Aaron Kamoske/Dropbox/Publications/Kamoske_Dissteration_Ch3/data/bioclim/mlbs2018_bioclim_20200205.csv")
harv.bio <- read.csv("C:/Users/Aaron Kamoske/Dropbox/Publications/Kamoske_Dissteration_Ch3/data/bioclim/harv2018_bioclim_20200205.csv")
colnames(all.avg) <- c("site", as.vector(rownames(tall.avg)), as.vector(colnames(tall.bio)[2:20]))
# create an empty data frame to store all this data in
all.avg <- data.frame(site = c("TALL", "SERC", "ORNL", "MLBS", "HARV"))
all.avg[,2:60] <- 0
colnames(all.avg) <- c("site", as.vector(rownames(tall.avg)), as.vector(colnames(tall.bio)[2:20]))
all.avg[1,2:60] <- c(tall.avg$`colMeans(tall.data)`, tall.bio[,2:20])
all.avg[2,2:60] <- c(serc.avg$`colMeans(serc.data)`, serc.bio[,2:20])
all.avg[3,2:60] <- c(ornl.avg$`colMeans(ornl.data)`, ornl.bio[,2:20])
all.avg[4,2:60] <- c(mlbs.avg$`colMeans(mlbs.data)`, mlbs.bio[,2:20])
all.avg[5,2:60] <- c(harv.avg$`colMeans(harv.data)`, harv.bio[,2:20])
# set the limit of correlation that is correlated
R <- 0.5
# remove the predictors that are too correlated
reduced.pred <- rem.cors(all.avg)
head(all.avg)
dim(all.avg)
# remove the predictors that are too correlated
reduced.pred <- rem.cors(all.avg[2:60])
# run an OLS with the above predictors
npp.model <- lm(npp ~ .,
data = reduced.pred)
summary(npp.model)
colnames(reduced.pred)
aic.model <- stepAIC(npp.model, k = 2, trace = F)
# split the NPP data from the rest of the data
tall.npp <- tall.data$npp
# split the NPP data from the rest of the data
tall.npp <- tall$npp
head(tall)
colnames(tall)
tall.var <- tall[,15:40]
colnames(tall.var)
# lets run a pca on the training data
tall.pca <- prcomp(tall.var,
center = TRUE,
scale. = TRUE)
# how well did this do
summary(tall.pca)
# look at the loading values to determine the influence of each variable on the individual PCs
tall.pca$rotation[,1]
# look at the loading values to determine the influence of each variable on the individual PCs
tall.pca$rotation[,2]
# look at the loading values to determine the influence of each variable on the individual PCs
tall.pca$rotation[,3]
# try a regression between some of these variables
tall.lm <- lm(tall.npp ~ tall.pca$x[,1])
summary(tall.lm)
plot(tall.pca$x[,1], tall.npp)
# try a regression between some of these variables
tall.lm <- lm(tall.npp ~ tall.pca$x[,2])
summary(tall.lm)
library(devtools)
setwd("C:/Users/Aaron Kamoske/Dropbox/R_Packages_GitHub/hypRspec")
devtools::document()
library(devtools)
devtools::document()
devtools::document()
devtools::document()
install_github("akamoske/hypRspec")
# list all the hdf5 files
hsi.files <- list.files("D:/corrected_hsi_hdf5_files/tall2018",
full.names = TRUE)
hsi.files
i <- 1
10000/27
hsi.refl <- hsi.random.extract(hy.file = hsi.files[i],
coordinate.path = "/TALL/Reflectance/Metadata/Coordinate_System",
wavelength.path = "/TALL/Reflectance/Metadata/Spectral_Data/Wavelength",
band.combo = c(25:194, 215:284, 325:403),
number.pts = 370)
hy.file = hsi.files[i]
coordinate.path = "/TALL/Reflectance/Metadata/Coordinate_System"
wavelength.path = "/TALL/Reflectance/Metadata/Spectral_Data/Wavelength"
band.combo = c(25:194, 215:284, 325:403)
number.pts = 370
# lets look at the reflectance metadata
refl.info <- h5readAttributes(hy.file, metadata.path)
metadata.path = "/TALL/Reflectance/Reflectance_Data"
# lets look at the reflectance metadata
refl.info <- h5readAttributes(hy.file, metadata.path)
h5closeAll()
# lets look at the reflectance metadata
refl.info <- h5readAttributes(hy.file, metadata.path)
# lets save the dimensions of the dataset for future use
n.rows <- refl.info$Dimensions[1]
n.cols <- refl.info$Dimensions[2]
n.bands <- refl.info$Dimensions[3]
# lets save the scale factor and the data ignore value
scale.fact.val <- refl.info$Scale_Factor
data.ignore.val <- refl.info$Data_Ignore_Value
# lets read in the wavelength info
wavelengths <- h5read(file = hy.file,
name = wavelength.path)
# read in the coordinate infomation
map.info <- h5read(file = hy.file,
name = coordinate.path)
# save the crs projection data
crs.proj <- base::paste0("+init=epsg:", map.info$`EPSG Code`)
# lets prevent R from writing the numbers in scientific format
options(scipen = 999)
# we need to make an empty matrix to store all the reflectance data in
ext.mat <- matrix(ncol = length(band.combo) + 2,
nrow = number.pts + 1)
# set the wavelength names
wl.names <- paste0("nm", wavelengths[band.combo])
# set the column names
ext.mat[1,1] <- "ID"
ext.mat[1,2] <- "Fline"
ext.mat[1, 3:ncol(ext.mat)] <- wl.names
# set the ID variable
ext.mat[2:nrow(ext.mat), 1] <- as.vector(1:number.pts)
# pull out the file name
clean.name <- tools::file_path_sans_ext(hy.file)
strsplit(clean.name, "/")
clean.name <- strsplit(clean.name, "/")[[1]][4]
strsplit(clean.name, "_")
ext.mat[2:nrow(ext.mat), 2] <- strsplit(clean.name, "_")[[1]][3]
# set the index for the matrix column
r <- 3
# start a new count for the loop
w <- 1
q <- 25
# lets read in the band and clean it up like we need before
refl.array <- h5read(file = hy.file,
name = reflectance.path,
index = list(q, 1:n.cols, 1:n.rows))
reflectance.path = "/TALL/Reflectance/Reflectance_Data"
# lets read in the band and clean it up like we need before
refl.array <- h5read(file = hy.file,
name = reflectance.path,
index = list(q, 1:n.cols, 1:n.rows))
refl.matrix <- refl.array[1,,]
refl.matrix[refl.matrix == data.ignore.val] <- NA
refl.matrix <- refl.matrix / scale.fact.val
# memory clean up
gc()
rm(refl.array)
gc()
# lets apply the masks to this band
refl.matrix <- ifelse(ndvi.mask, refl.matrix, NA)
print(paste0("extracting data from band ", q, "."))
# convert the matrix to a raster
refl.raster <- raster(topo.matrix, crs = crs.proj)
# convert the matrix to a raster
refl.raster <- raster(refl.matrix, crs = crs.proj)
# we need to transpose the raster
refl.raster <- raster::t(refl.raster)
# find the dimensions of our raster
y.dim <- dim(refl.raster)[1]
x.dim <- dim(refl.raster)[2]
# set the x.max and y.min
x.max <- x.min + x.dim
y.min <- y.max - y.dim
# create an extent object
raster.ext <- extent(x.min, x.max, y.min, y.max)
# set the spatial extent of the raster
extent(refl.raster) <- raster.ext
# pull out the map extent info
map.inform <- strsplit(map.info$Map_Info, split = ",", fixed = TRUE)
map.inform
x.min <- as.numeric(map.inform[[1]][4])
y.max <- as.numeric(map.inform[[1]][5])
# convert the matrix to a raster
refl.raster <- raster(refl.matrix, crs = crs.proj)
# we need to transpose the raster
refl.raster <- raster::t(refl.raster)
# find the dimensions of our raster
y.dim <- dim(refl.raster)[1]
x.dim <- dim(refl.raster)[2]
# set the x.max and y.min
x.max <- x.min + x.dim
y.min <- y.max - y.dim
# create an extent object
raster.ext <- extent(x.min, x.max, y.min, y.max)
# set the spatial extent of the raster
extent(refl.raster) <- raster.ext
plot(refl.raster)
# lets extract the reflectance data
ref.toc <- sampleRandom(refl.raster, size = number.pts, na.rm = TRUE, sp = TRUE)
# now we want to save the extracted data
ref.data <- ref.toc@data
# lets add this into the right part of the matrix
ext.mat[2:nrow(ext.mat), r] <- as.vector(ref.data$layer)
head(ext.mat)
library(devtools)
setwd("C:/Users/Aaron Kamoske/Dropbox/R_Packages_GitHub/hypRspec")
devtools::document()
devtools::document()
install_github("akamoske/hypRspec")
library(hypRspec)
# list all the hdf5 files
hsi.files <- list.files("D:/corrected_hsi_hdf5_files/tall2018",
full.names = TRUE)
i <- 1
hsi.refl <- hsi.random.extract(hy.file = hsi.files[i],
metadata.path = "/TALL/Reflectance/Reflectance_Data",
coordinate.path = "/TALL/Reflectance/Metadata/Coordinate_System",
wavelength.path = "/TALL/Reflectance/Metadata/Spectral_Data/Wavelength",
reflectance.path = "/TALL/Reflectance/Reflectance_Data",
band.combo = c(25:194, 215:284, 325:403),
number.pts = 370)
strsplit(hsi.files[i], "_")
library(hypRspec)
# list all the hdf5 files
hsi.files <- list.files("D:/corrected_hsi_hdf5_files/tall2018",
full.names = TRUE)
# loop through the files and extract the data
for (i in 1:length(hsi.files)) {
# extract the data for the flight line
hsi.refl <- hsi.random.extract(hy.file = hsi.files[i],
metadata.path = "/TALL/Reflectance/Reflectance_Data",
coordinate.path = "/TALL/Reflectance/Metadata/Coordinate_System",
wavelength.path = "/TALL/Reflectance/Metadata/Spectral_Data/Wavelength",
reflectance.path = "/TALL/Reflectance/Reflectance_Data",
band.combo = c(25:194, 215:284, 325:403),
number.pts = 370)
# pull out the file name
f.name <- strsplit(hsi.files[i], "_")[[1]][6]
# write this to a csv file
write.csv(x = hsi.refl,
file = paste0("C:/Users/Aaron Kamoske/Dropbox/Publications/Kamoske_Dissteration_Ch3/",
"data/spectral_diversity/monte_carlo/reflectance/flightlines/",
"TALL2018_", f.name, "_Reflectance.csv"),
row.names = FALSE)
}
# list the flightline csvs
fl.csv <- list.files(paste0("C:/Users/Aaron Kamoske/Dropbox/Publications/Kamoske_Dissteration_Ch3/",
"data/spectral_diversity/monte_carlo/reflectance/flightlines",
full.names = TRUE))
fl.csv
# list the flightline csvs
fl.csv <- list.files(paste0("C:/Users/Aaron Kamoske/Dropbox/Publications/Kamoske_Dissteration_Ch3/",
"data/spectral_diversity/monte_carlo/reflectance/flightlines"),
full.names = TRUE)
fl.csv
# read in the flightline csvs and merge them together
site.refl <- do.call(rbind, lapply(fl.csv, read.csv, skip = 1))
head(site.refl)
# lets remove the flightline column
site.refl$Fline <- NULL
# lets remove the id column
site.refl$ID <- NULL
head(site.refl)
# lets remove the flightline column
site.refl$Fline <- NULL
# lets remove the id column
site.refl$ID <- NULL
colnames(site.refl)
# lets run a pca on the training data
site.pca <- prcomp(site.refl,
center = TRUE,
scale = FALSE)
summary(site.pca)
# calculate the total variance of the first 3 PCs
tot.var <- var(site.pca$x[,1]) + var(site.pca$x[,2]) + var(site.pca$x[,3])
tot.var
# calculate a convex hull
c.mat <- cbind(site.pca$x[,1], site.pca$x[,2], site.pca$x[,3])
con.h <- convhulln(c.mat, options = "FA")$vol
con.h
# make an empty matrix to store the final results in
final.mat <- matrix(0, nrow = 6, ncol = 3)
final.mat[1,] <- c("Run", "Tot.Var", "Conv.H")
final.mat[2:6,1] <- c(1:5)
# write these to the final matrix
final.mat[a,2] <- tot.var
a <- 2
# write these to the final matrix
final.mat[a,2] <- tot.var
final.mat[a,3] <- con.h
final.mat
# write this to a csv file
write.csv(x = final.mat,
file = paste0("C:/Users/Aaron Kamoske/Dropbox/Publications/Kamoske_Dissteration_Ch3/",
"data/spectral_diversity/monte_carlo/",
"TALL2018_MC_Results.csv"),
row.names = FALSE)
library(hypRspec)
library(geometry)
# list all the hdf5 files
hsi.files <- list.files("D:/corrected_hsi_hdf5_files/tall2018",
full.names = TRUE)
# make an empty matrix to store the final results in
final.mat <- matrix(0, nrow = 6, ncol = 3)
final.mat[1,] <- c("Run", "Tot.Var", "Conv.H")
final.mat[2:6,1] <- c(1:5)
# run a monte carlo simulation 5 times to see how our results vary
for (a in 2:6) {
# loop through the files and extract the data
for (i in 1:length(hsi.files)) {
# extract the data for the flight line
hsi.refl <- hsi.random.extract(hy.file = hsi.files[i],
metadata.path = "/TALL/Reflectance/Reflectance_Data",
coordinate.path = "/TALL/Reflectance/Metadata/Coordinate_System",
wavelength.path = "/TALL/Reflectance/Metadata/Spectral_Data/Wavelength",
reflectance.path = "/TALL/Reflectance/Reflectance_Data",
band.combo = c(25:194, 215:284, 325:403),
number.pts = 370)
# pull out the file name
f.name <- strsplit(hsi.files[i], "_")[[1]][6]
# write this to a csv file
write.csv(x = hsi.refl,
file = paste0("C:/Users/Aaron Kamoske/Dropbox/Publications/Kamoske_Dissteration_Ch3/",
"data/spectral_diversity/monte_carlo/reflectance/",
"TALL2018_", f.name, "_Reflectance.csv"),
row.names = FALSE)
}
# list the flightline csvs
fl.csv <- list.files(paste0("C:/Users/Aaron Kamoske/Dropbox/Publications/Kamoske_Dissteration_Ch3/",
"data/spectral_diversity/monte_carlo/reflectance"),
full.names = TRUE)
# read in the flightline csvs and merge them together
site.refl <- do.call(rbind, lapply(fl.csv, read.csv, skip = 1))
# lets remove the flightline column
site.refl$Fline <- NULL
# lets remove the id column
site.refl$ID <- NULL
# lets run a pca on the training data
site.pca <- prcomp(site.refl,
center = TRUE,
scale = FALSE)
# calculate the total variance of the first 3 PCs
tot.var <- var(site.pca$x[,1]) + var(site.pca$x[,2]) + var(site.pca$x[,3])
# calculate a convex hull
c.mat <- cbind(site.pca$x[,1], site.pca$x[,2], site.pca$x[,3])
con.h <- convhulln(c.mat, options = "FA")$vol
# write these to the final matrix
final.mat[a,2] <- tot.var
final.mat[a,3] <- con.h
# write this to a csv file
write.csv(x = final.mat,
file = paste0("C:/Users/Aaron Kamoske/Dropbox/Publications/Kamoske_Dissteration_Ch3/",
"data/spectral_diversity/monte_carlo/",
"TALL2018_MC_Results.csv"),
row.names = FALSE)
}
# list the flightline csvs
fl.csv <- list.files(paste0("C:/Users/Aaron Kamoske/Dropbox/Publications/Kamoske_Dissteration_Ch3/",
"data/spectral_diversity/monte_carlo/reflectance"),
full.names = TRUE)
# read in the flightline csvs and merge them together
site.refl <- do.call(rbind, lapply(fl.csv, read.csv, skip = 1))
# lets remove the flightline column
site.refl$Fline <- NULL
# lets remove the id column
site.refl$ID <- NULL
# lets run a pca on the training data
site.pca <- prcomp(site.refl,
center = TRUE,
scale = FALSE)
# calculate the total variance of the first 3 PCs
tot.var <- var(site.pca$x[,1]) + var(site.pca$x[,2]) + var(site.pca$x[,3])
# calculate a convex hull
c.mat <- cbind(site.pca$x[,1], site.pca$x[,2], site.pca$x[,3])
con.h <- convhulln(c.mat, options = "FA")$vol
# write these to the final matrix
final.mat[a,2] <- tot.var
final.mat[a,3] <- con.h
# write this to a csv file
write.csv(x = final.mat,
file = paste0("C:/Users/Aaron Kamoske/Dropbox/Publications/Kamoske_Dissteration_Ch3/",
"data/spectral_diversity/monte_carlo/",
"TALL2018_MC_Results.csv"),
row.names = FALSE)
# run a monte carlo simulation 5 times to see how our results vary
for (a in 3:6) {
# loop through the files and extract the data
for (i in 1:5) {
# extract the data for the flight line
hsi.refl <- hsi.random.extract(hy.file = hsi.files[i],
metadata.path = "/TALL/Reflectance/Reflectance_Data",
coordinate.path = "/TALL/Reflectance/Metadata/Coordinate_System",
wavelength.path = "/TALL/Reflectance/Metadata/Spectral_Data/Wavelength",
reflectance.path = "/TALL/Reflectance/Reflectance_Data",
band.combo = c(25:194, 215:284, 325:403),
number.pts = 1000)
# pull out the file name
f.name <- strsplit(hsi.files[i], "_")[[1]][6]
# write this to a csv file
write.csv(x = hsi.refl,
file = paste0("C:/Users/Aaron Kamoske/Dropbox/Publications/Kamoske_Dissteration_Ch3/",
"data/spectral_diversity/monte_carlo/reflectance/",
"TALL2018_", f.name, "_Reflectance.csv"),
row.names = FALSE)
}
# list the flightline csvs
fl.csv <- list.files(paste0("C:/Users/Aaron Kamoske/Dropbox/Publications/Kamoske_Dissteration_Ch3/",
"data/spectral_diversity/monte_carlo/reflectance"),
full.names = TRUE)
# read in the flightline csvs and merge them together
site.refl <- do.call(rbind, lapply(fl.csv, read.csv, skip = 1))
# lets remove the flightline column
site.refl$Fline <- NULL
# lets remove the id column
site.refl$ID <- NULL
# lets run a pca on the training data
site.pca <- prcomp(site.refl,
center = TRUE,
scale = FALSE)
# calculate the total variance of the first 3 PCs
tot.var <- var(site.pca$x[,1]) + var(site.pca$x[,2]) + var(site.pca$x[,3])
# calculate a convex hull
c.mat <- cbind(site.pca$x[,1], site.pca$x[,2], site.pca$x[,3])
con.h <- convhulln(c.mat, options = "FA")$vol
# write these to the final matrix
final.mat[a,2] <- tot.var
final.mat[a,3] <- con.h
# write this to a csv file
write.csv(x = final.mat,
file = paste0("C:/Users/Aaron Kamoske/Dropbox/Publications/Kamoske_Dissteration_Ch3/",
"data/spectral_diversity/monte_carlo/",
"TALL2018_MC_Results.csv"),
row.names = FALSE)
}
